#!/usr/bin/python3

################################################################################
#
# Copyright (c) 2022 Bequant S.L.
# All rights reserved.
#
# This product or document is proprietary to and embodies the
# confidential technology of Bequant S.L., Spain.
# Possession, use, duplication or distribution of this product
# or document is authorized only pursuant to a valid written
# license from Bequant S.L.
#
#
################################################################################

import json
import argparse
import re
import datetime
import base64

import requests
if not requests.__version__.startswith("1."):
  # Avoid insecure warning when issuing REST queries
  import urllib3
  urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

from BillingSync import BillingSync

################################################################################

class Ixc(BillingSync):

  ############################################################################

  def getPagedEntries(self, server, key, query, pageSize=10000, maxPages=1000, filter=None):
    url =  "https://" + server + "/webservice/v1" + query
    credentials = base64.b64encode(key.encode("utf-8")).decode("utf-8")
    headers = {
      "content-type": "application/json;charset=UTF-8",
      "Accept-Charset": "UTF-8",
      "Accept": "application/json",
      "Connection": "keep-alive",
      'ixcsoft': 'listar',
      "Authorization": "Basic %s" % credentials
    }

    page = 1
    remaining = True
    entries = []

    queryJson = {
        'rp': str(pageSize),    # 10K quicker than 1K (45% less time in our testing of 60K entries)
    }
    if filter:
      for k in filter:
        queryJson[k] = filter[k]

    while remaining and page <= maxPages:
      self.logger.info("POST to %s, page %d" % (url, page))
      queryJson['page'] = str(page)
      rsp = requests.post(url, headers=headers,  data=self.jsonDumps(queryJson), verify=False)
      self.printResponseDetails(rsp)
      if rsp.status_code != 200:
        # We continue with one page error to allow for partial synchronizations, given the long
        # sync needed in the case of this billing system
        self.logger.error("Bad query %d (page %d). Continue with next page." % (rsp.status_code, page))
        continue
      rspJson = json.loads(rsp.text)
      if not "registros" in rspJson:
        self.logger.error("Page %d not returned by query. End query." % page)
        break
      entries += rspJson["registros"]
      total = int(rspJson["total"])
      remaining = (total > len(entries))
      page += 1

    return entries

  ############################################################################

  def convertToKbps(self, str):
    matches = re.search("(\d+)\s*([kKmMgG]\s*)", str)
    if not matches or len(matches.groups()) != 2:
      return -1
    value = matches.groups()[0]
    units = matches.groups()[1]
    if units == 'k' or units == 'K':
      return int(value)
    elif units == 'm' or units == 'M':
      return int(value)*1000
    elif units == 'g' or units == 'G':
      return int(value)*10**6
    else:
      return -1

  def normalizeData(self, radusuarios, radgrupos, contratos, dualStack):
    """
    radusuarios:
      online = 'S' (with an active session)
      id_cliente -> clientes.id
      id_contrato -> contratos.id
      id_grupo -> radgrupo.id
      ip: ipv4 address
      pd_ipv6: ipv6 address (delegated prefix)
    
    radgrupos:
      id <- radusuarios.id_grupo
      grupo: name of policy
      upload: uplink speed limit as string of format <number><units>
      download: downlink speed limit as string of format <number><units>
      tipo: "I" (Internet, Telefonia, Service)
    
    contratos:
      id <- radusuarios.id_contrato
      id_cliente -> clientes.id
      status_internet:
        Allowed status: A (ativo) and FA (Financieiro em atraso)
        Blocked status: rest. D (deactivado), CM (bloqueo manual), CA (bloqueo automarito), AA (Aguardando Assinatura)

    clientes:
      id <- radusuarios.id_cliente
      razao: customer name
      (razao not used as subscriber ID because it is not unique per radusuario)
    """
    data = {'subscribers': [], 'policies': [], 'subscriberGroups': []}
    
    for p in radgrupos:
      if p["tipo"] != "I":
        continue
      policy = {
        "policyName": p["grupo"],
        "policyId": str(p["id"]),
        "rateLimitUplink": {},
        "rateLimitDownlink": {}
      }
      policy["rateLimitUplink"]["rate"] = self.convertToKbps(p["upload"])
      policy["rateLimitDownlink"]["rate"] = self.convertToKbps(p["download"])
      data["policies"].append(policy)

    # Create dictionaries for searchable lists to speed up processing
    radgruposDct = {}
    for x in radgrupos:
      radgruposDct[x["id"]] = x
    contratosDct = {}
    for x in contratos:
      contratosDct[x["id"]] = x

    for rdu in radusuarios:
      # If no IP or not online, it makes no sense to continue
      if not "ip" in rdu or rdu['online'] != 'S':
        self.logger.warning("Subscriber %s not online, ignored" % rdu["login"])
        continue
  
      subscriber = {} 
      subscriber["subscriberIp"] = rdu['ip']
      subscriber["subscriberId"] = rdu['login']

      # Look for policy
      if not rdu['id_grupo'] in radgruposDct:
        # Subscriber has no associated policy (include cases of 'id_group' == '0').
        self.logger.warning("Subscriber %s with unknown policy of name %s" % (rdu["login"], rdu['id_grupo']))
        subscriber["policyRate"] = None
      else:
        subscriber["policyRate"] = radgruposDct[rdu['id_grupo']]['grupo']

      # Look for contract
      if not contratos:
         subscriber["state"] = "Unknown"
         subscriber["block"] = False
      else:
        if not rdu['id_contrato'] in contratosDct:
          self.logger.warning("Radusuario %s with unknown contract id %s" % (rdu['login'], rdu['id_contrato']))
          subscriber["state"] = "Unknown"
          subscriber["block"] = False
        else:
          contract = contratosDct[rdu['id_contrato']]
          subscriber["state"] = contract['status_internet']
          subscriber["block"] = not contract['status_internet'] == 'A' and not contract['status_internet'] == 'FA'
  
      data["subscribers"].append(subscriber)

      if dualStack and subscriber["policyRate"] and "pd_ipv6" in rdu and rdu["pd_ipv6"]:
        # Define a Subscriber Group with all IP addresses
        subGroup = {}
        subGroup["subscriberGroupName"] = "DS-%s" % subscriber['subscriberId']
        subGroup["policyRate"] = subscriber["policyRate"]
        subGroup["subscriberMembers"] = [rdu['ip']]
        subGroup["subscriberRanges"] = [rdu['pd_ipv6']]
        data["subscriberGroups"].append(subGroup)
  
    return data

################################################################################

if __name__ == "__main__":

  parser = argparse.ArgumentParser(
    description="""
  Synchronizes speed limits in IXC with BQN rate policies.

  Requires an API KEY in UISP and the REST API enabled in BQN.

  TODO: add dual stack option and max pages option

  Known limitations:
  - Synchronization may take several minutes.
  - If the synchronization fails, no retry is attempted (must be done externally).
  - No scheduling of script execution (must be done externally).
  """, formatter_class=argparse.RawTextHelpFormatter)

  parser.add_argument('-b', help='BQN address and REST credentials. If absent, no BQN synchromization',
                      nargs=3, metavar=('BQN-IP', 'REST-USER', 'REST-PW'), dest='bqn')
  parser.add_argument('-v', '--verbose', action='count', dest='verbose', default=0,
                    help="Display extra informationt (repeat for increased verbosity)")
  parser.add_argument('-ds', '--dual-stack', action='store_true', dest="dualStack", default=False, 
      help='Group v4 and v6 IP addresses of some subscriber under same rate limit. If absent, no group created')
  parser.add_argument('-ps', '--page-size', default=10000, type=int, dest="pageSize", \
      help='Number of entries retrieved per page. 10000 by default (balance between speed and IXC server load)')
  parser.add_argument('-mp', '--max-pages', default=100, type=int, dest="maxPages", \
      help='Maximum number of pages to retrieve per query. For test only (leads to partial synchronizations)')
  parser.add_argument('-lf', '--log-file', default=None, type=str, dest="logFile",
      help='Log file to use. If absent, logs go to statd output')
  parser.add_argument('billingHost', metavar='IXC-HOST', type=str, help='IXC URL')
  parser.add_argument('key', metavar='API-KEY', type=str, help=' IXC REST API key')
  args = parser.parse_args()

  billingSync = Ixc(args.verbose, args.logFile)
  billingSync.logger.warning("%s synchronization script starts (v1.0)" % datetime.datetime.now())

  billingHost = args.billingHost.replace("https://", "")

  radusuarios = billingSync.getPagedEntries(billingHost, args.key, '/radusuarios', pageSize=args.pageSize, maxPages=args.maxPages,
                                filter = {
                                  'qtype': 'radusuarios.online',
                                  'oper': '=',
                                  'query': 'S'
                                })
  """
  Alternative with advanced grid_param:
   filter = {
      'grid_param': [{"TB":"radusuarios.online", "OP":"=", "P":"S"}]
    }
  """
  radgrupos = billingSync.getPagedEntries(billingHost, args.key, '/radgrupos', pageSize=args.pageSize, maxPages=args.maxPages)
  contratos = billingSync.getPagedEntries(billingHost, args.key, '/cliente_contrato', pageSize=args.pageSize, maxPages=args.maxPages)

  billingSync.logger.warning("%s queries to billing completed" % datetime.datetime.now())


  data = billingSync.normalizeData(radusuarios, radgrupos, contratos, args.dualStack)
  billingSync.logger.warning("%s data normalization completed" % datetime.datetime.now())
  if args.verbose > 0:
    billingSync.printData(data)
  if args.bqn:
    billingSync.updateBqn(args.bqn[0], args.bqn[1], args.bqn[2], data)

  billingSync.logger.warning("%s synchronization script ends" % datetime.datetime.now())






